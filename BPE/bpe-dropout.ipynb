{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107ef8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cf31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = \"/home/nmt_shared/training_data/raw/commoncrawl/commoncrawl.fr-en.fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe56347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/nmt_shared/training_data/raw/commoncrawl/commoncrawl.fr-en.fr\n",
      "  input_format: \n",
      "  model_prefix: dropout_10\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 160\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /home/nmt_shared/training_data/raw/commoncrawl/commoncrawl.fr-en.fr\n",
      "trainer_interface.cc(356) LOG(WARNING) Found too long line (5343 > 4192).\n",
      "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (3244086), which may slow down training.\n",
      "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 3244086 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Skipped 66 too long sentences.\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=483306313\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9509% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=131\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999509\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 3244086 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 1000000 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 3244086\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 2045884\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 2045884 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=516435 obj=12.3841 num_tokens=5585699 num_tokens/piece=10.8159\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=449651 obj=9.66145 num_tokens=5584502 num_tokens/piece=12.4196\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=337225 obj=9.63295 num_tokens=5674884 num_tokens/piece=16.8282\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=337102 obj=9.62917 num_tokens=5675933 num_tokens/piece=16.8374\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=252825 obj=9.64874 num_tokens=5866899 num_tokens/piece=23.2054\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=252822 obj=9.64625 num_tokens=5866645 num_tokens/piece=23.2046\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=189616 obj=9.68528 num_tokens=6103204 num_tokens/piece=32.1872\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=189616 obj=9.67869 num_tokens=6102787 num_tokens/piece=32.185\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=142212 obj=9.73467 num_tokens=6348923 num_tokens/piece=44.6441\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=142212 obj=9.72306 num_tokens=6348733 num_tokens/piece=44.6427\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=106659 obj=9.79845 num_tokens=6605473 num_tokens/piece=61.9308\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=106659 obj=9.78477 num_tokens=6605651 num_tokens/piece=61.9324\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=79994 obj=9.8775 num_tokens=6871644 num_tokens/piece=85.902\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=79994 obj=9.86036 num_tokens=6871987 num_tokens/piece=85.9063\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=59995 obj=9.9739 num_tokens=7151996 num_tokens/piece=119.21\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=59995 obj=9.95276 num_tokens=7152624 num_tokens/piece=119.22\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=44996 obj=10.0907 num_tokens=7442124 num_tokens/piece=165.395\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=44996 obj=10.0647 num_tokens=7443104 num_tokens/piece=165.417\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=33747 obj=10.2286 num_tokens=7750264 num_tokens/piece=229.658\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=33747 obj=10.1964 num_tokens=7751063 num_tokens/piece=229.682\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25310 obj=10.3901 num_tokens=8059745 num_tokens/piece=318.441\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25310 obj=10.3513 num_tokens=8062385 num_tokens/piece=318.545\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=18982 obj=10.5778 num_tokens=8389734 num_tokens/piece=441.984\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=18982 obj=10.531 num_tokens=8391820 num_tokens/piece=442.094\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14236 obj=10.7924 num_tokens=8738497 num_tokens/piece=613.831\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14236 obj=10.7371 num_tokens=8741475 num_tokens/piece=614.04\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10677 obj=11.0427 num_tokens=9089082 num_tokens/piece=851.277\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10677 obj=10.9789 num_tokens=9094353 num_tokens/piece=851.77\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8007 obj=11.3238 num_tokens=9466337 num_tokens/piece=1182.26\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8007 obj=11.2482 num_tokens=9468168 num_tokens/piece=1182.49\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6005 obj=11.6318 num_tokens=9867891 num_tokens/piece=1643.28\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6005 obj=11.5477 num_tokens=9878791 num_tokens/piece=1645.09\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=4503 obj=11.9811 num_tokens=10274376 num_tokens/piece=2281.67\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=4503 obj=11.884 num_tokens=10275333 num_tokens/piece=2281.89\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3377 obj=12.3592 num_tokens=10702795 num_tokens/piece=3169.32\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3377 obj=12.2577 num_tokens=10703368 num_tokens/piece=3169.49\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2532 obj=12.7858 num_tokens=11130793 num_tokens/piece=4396.05\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2532 obj=12.67 num_tokens=11131449 num_tokens/piece=4396.31\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1899 obj=13.2333 num_tokens=11583685 num_tokens/piece=6099.89\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1899 obj=13.1083 num_tokens=11583897 num_tokens/piece=6100\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1424 obj=13.7089 num_tokens=11982814 num_tokens/piece=8414.9\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1424 obj=13.5558 num_tokens=11989472 num_tokens/piece=8419.57\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1068 obj=14.1872 num_tokens=12342685 num_tokens/piece=11556.8\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1068 obj=14.0475 num_tokens=12343625 num_tokens/piece=11557.7\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=801 obj=14.7321 num_tokens=12737114 num_tokens/piece=15901.5\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=801 obj=14.5781 num_tokens=12737844 num_tokens/piece=15902.4\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=600 obj=15.2989 num_tokens=13172115 num_tokens/piece=21953.5\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=600 obj=15.123 num_tokens=13172613 num_tokens/piece=21954.4\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=450 obj=15.9542 num_tokens=13730038 num_tokens/piece=30511.2\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=450 obj=15.7193 num_tokens=13732453 num_tokens/piece=30516.6\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=337 obj=16.6285 num_tokens=14533505 num_tokens/piece=43126.1\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=337 obj=16.3241 num_tokens=14534708 num_tokens/piece=43129.7\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=252 obj=17.4707 num_tokens=15822997 num_tokens/piece=62789.7\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=252 obj=16.9827 num_tokens=15823057 num_tokens/piece=62789.9\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=189 obj=18.4794 num_tokens=17221419 num_tokens/piece=91118.6\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=189 obj=17.8442 num_tokens=17258498 num_tokens/piece=91314.8\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=176 obj=18.2612 num_tokens=17483379 num_tokens/piece=99337.4\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=176 obj=18.0911 num_tokens=17483380 num_tokens/piece=99337.4\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: dropout_10.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: dropout_10.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=textfile,model_prefix='dropout_10',vocab_size=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1b9f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'or', 'k']\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor(model_file='dropout_10.model')\n",
    "for n in range(5):\n",
    "    print(s.encode('New York', out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95981a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n",
      "['▁', 'N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Subword regularization and BPE-dropout et Subword regularization [Kudo.] et labandon du BPE Provilkov et al sont \n",
    "des méthodes de régularisation simples qui augmentent virtuellement les données dapprentissage avec un échantillonnage de sous\n",
    "-mots à la volée, ce qui contribue à améliorer la précision ainsi que la robustesse des modèles NMT.\"\"\"\n",
    "\n",
    "s = spm.SentencePieceProcessor(model_file='dropout_2.model')\n",
    "for n in range(5):\n",
    "    print(s.encode('New York', out_type=str, enable_sampling=True, alpha=0.1, nbest_size=-1))\n",
    "    \"\"\"`alpha` est la probabilité d'abandon `p` des opérations de fusion bpe\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130a1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/nmt_shared/training_data/raw/commoncrawl/commoncrawl.fr-en.fr\n",
      "  input_format: \n",
      "  model_prefix: dropout_20\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /home/nmt_shared/training_data/raw/commoncrawl/commoncrawl.fr-en.fr\n",
      "trainer_interface.cc(356) LOG(WARNING) Found too long line (5343 > 4192).\n",
      "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (3244086), which may slow down training.\n",
      "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 3244086 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Skipped 66 too long sentences.\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=483306313\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9509% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=131\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999509\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 3244086 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 1000000 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 3244086\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 2045884\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 2045884 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=516435 obj=12.3841 num_tokens=5585699 num_tokens/piece=10.8159\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=449651 obj=9.66145 num_tokens=5584502 num_tokens/piece=12.4196\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=337225 obj=9.63295 num_tokens=5674884 num_tokens/piece=16.8282\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=337102 obj=9.62917 num_tokens=5675933 num_tokens/piece=16.8374\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=252825 obj=9.64874 num_tokens=5866899 num_tokens/piece=23.2054\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=252822 obj=9.64625 num_tokens=5866645 num_tokens/piece=23.2046\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=189616 obj=9.68528 num_tokens=6103204 num_tokens/piece=32.1872\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=189616 obj=9.67869 num_tokens=6102787 num_tokens/piece=32.185\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=142212 obj=9.73467 num_tokens=6348923 num_tokens/piece=44.6441\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=142212 obj=9.72306 num_tokens=6348733 num_tokens/piece=44.6427\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=106659 obj=9.79845 num_tokens=6605473 num_tokens/piece=61.9308\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=106659 obj=9.78477 num_tokens=6605651 num_tokens/piece=61.9324\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=79994 obj=9.8775 num_tokens=6871644 num_tokens/piece=85.902\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=79994 obj=9.86036 num_tokens=6871987 num_tokens/piece=85.9063\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=59995 obj=9.9739 num_tokens=7151996 num_tokens/piece=119.21\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=59995 obj=9.95276 num_tokens=7152624 num_tokens/piece=119.22\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=44996 obj=10.0907 num_tokens=7442124 num_tokens/piece=165.395\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=44996 obj=10.0647 num_tokens=7443104 num_tokens/piece=165.417\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=33747 obj=10.2286 num_tokens=7750264 num_tokens/piece=229.658\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=33747 obj=10.1964 num_tokens=7751063 num_tokens/piece=229.682\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25310 obj=10.3901 num_tokens=8059745 num_tokens/piece=318.441\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25310 obj=10.3513 num_tokens=8062385 num_tokens/piece=318.545\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=18982 obj=10.5778 num_tokens=8389734 num_tokens/piece=441.984\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=18982 obj=10.531 num_tokens=8391820 num_tokens/piece=442.094\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14236 obj=10.7924 num_tokens=8738497 num_tokens/piece=613.831\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14236 obj=10.7371 num_tokens=8741475 num_tokens/piece=614.04\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10677 obj=11.0427 num_tokens=9089082 num_tokens/piece=851.277\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10677 obj=10.9789 num_tokens=9094353 num_tokens/piece=851.77\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8007 obj=11.3238 num_tokens=9466337 num_tokens/piece=1182.26\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8007 obj=11.2482 num_tokens=9468168 num_tokens/piece=1182.49\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=6005 obj=11.6318 num_tokens=9867891 num_tokens/piece=1643.28\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=6005 obj=11.5477 num_tokens=9878791 num_tokens/piece=1645.09\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=4503 obj=11.9811 num_tokens=10274376 num_tokens/piece=2281.67\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=4503 obj=11.884 num_tokens=10275333 num_tokens/piece=2281.89\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3377 obj=12.3592 num_tokens=10702795 num_tokens/piece=3169.32\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3377 obj=12.2577 num_tokens=10703368 num_tokens/piece=3169.49\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2532 obj=12.7858 num_tokens=11130793 num_tokens/piece=4396.05\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2532 obj=12.67 num_tokens=11131449 num_tokens/piece=4396.31\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1899 obj=13.2333 num_tokens=11583685 num_tokens/piece=6099.89\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1899 obj=13.1083 num_tokens=11583897 num_tokens/piece=6100\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1424 obj=13.7089 num_tokens=11982814 num_tokens/piece=8414.9\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1424 obj=13.5558 num_tokens=11989472 num_tokens/piece=8419.57\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1100 obj=14.1144 num_tokens=12323866 num_tokens/piece=11203.5\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1100 obj=13.991 num_tokens=12324917 num_tokens/piece=11204.5\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: dropout_20.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: dropout_20.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=textfile,model_prefix='dropout_20',vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9e21dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor(model_file='dropout_20.model')\n",
    "for n in range(5):\n",
    "    print(s.encode('New York', out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ca7665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'or', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n",
      "['▁N', 'e', 'w', '▁', 'Y', 'o', 'r', 'k']\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor(model_file='dropout_20.model')\n",
    "for n in range(5):\n",
    "    print(s.encode('New York', out_type=str, enable_sampling=True, alpha=0.1, nbest_size=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8824c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6247d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cce507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
